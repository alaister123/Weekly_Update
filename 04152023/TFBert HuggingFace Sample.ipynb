{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd132b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.16454318]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5d0132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gj04</th>\n",
       "      <th>1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Our friends won't buy this analysis, let alone the next one we propose.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One more pseudo generalization and I'm giving up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One more pseudo generalization or I'm giving up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The more we study verbs, the crazier they get.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Day by day the facts are getting murkier.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'll fix you a drink.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8545</th>\n",
       "      <td>ad03</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Poseidon appears to own a dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8546</th>\n",
       "      <td>ad03</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Digitize is my happiest memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8547</th>\n",
       "      <td>ad03</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It is easy to slay the Gorgon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8548</th>\n",
       "      <td>ad03</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I had the strangest feeling that I knew you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8549</th>\n",
       "      <td>ad03</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What all did you get for Christmas?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8550 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gj04  1 Unnamed: 2  \\\n",
       "0     gj04  1        NaN   \n",
       "1     gj04  1        NaN   \n",
       "2     gj04  1        NaN   \n",
       "3     gj04  1        NaN   \n",
       "4     gj04  1        NaN   \n",
       "...    ... ..        ...   \n",
       "8545  ad03  0          *   \n",
       "8546  ad03  0          *   \n",
       "8547  ad03  1        NaN   \n",
       "8548  ad03  1        NaN   \n",
       "8549  ad03  1        NaN   \n",
       "\n",
       "     Our friends won't buy this analysis, let alone the next one we propose.  \n",
       "0     One more pseudo generalization and I'm giving up.                       \n",
       "1      One more pseudo generalization or I'm giving up.                       \n",
       "2        The more we study verbs, the crazier they get.                       \n",
       "3             Day by day the facts are getting murkier.                       \n",
       "4                                 I'll fix you a drink.                       \n",
       "...                                                 ...                       \n",
       "8545                   Poseidon appears to own a dragon                       \n",
       "8546                     Digitize is my happiest memory                       \n",
       "8547                     It is easy to slay the Gorgon.                       \n",
       "8548       I had the strangest feeling that I knew you.                       \n",
       "8549                What all did you get for Christmas?                       \n",
       "\n",
       "[8550 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e53ebed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c0eb954",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac722a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = df['Our friends won\\'t buy this analysis, let alone the next one we propose.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "651956bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = np.array(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d4b4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a74a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in sentence:\n",
    "    data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6235ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = tokenizer(data[0:200], return_tensors=\"np\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45c6ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = dict(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c22973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "# Load and compile our model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
    "# Lower learning rates are often better for fine-tuning transformers\n",
    "model.compile(optimizer=Adam(3e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a31b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7/7 [==============================] - 64s 5s/step - loss: 0.6467\n",
      "Epoch 2/2\n",
      "7/7 [==============================] - 32s 4s/step - loss: 0.5892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa5a53ee20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tokenized_data, label[0:200], epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aac84f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 11s 1s/step\n"
     ]
    }
   ],
   "source": [
    "logits = model.predict(tokenized_data).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8933737",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_id = int(tf.math.argmax(logits, axis=-1)[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d62d2a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb07f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0944ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
